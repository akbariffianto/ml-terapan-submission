# -*- coding: utf-8 -*-
"""Real Estate Valuation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nL70F3OoZPaC9jvrMW2nuoqpH_VWCNhN

#Data Loading
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

url = '/content/Real estate valuation data set.xlsx'
realestate = pd.read_excel(url)
realestate

"""1. Nilai Kategori (Discrete):
  - No: Nomor urut (tidak relevan untuk analisis).
  - X4 number of convenience stores: Jumlah toko serba ada (bernilai diskrit, seperti 0, 1, 2, dll).
2. Nilai Kontinu (Continuous):
  - X1 transaction date: Tanggal transaksi (dalam format tahun desimal).
  - X2 house age: Usia rumah (tahun).
  - X3 distance to the nearest MRT station: Jarak ke stasiun MRT (meter).
  - X5 latitude: Lintang (koordinat geografis).
  - X6 longitude: Bujur (koordinat geografis).
  - Y house price of unit area: Harga rumah per unit area (kemungkinan dalam satuan moneter per meter persegi).

#Exploratory Data Analysis

##Deskripsi Variabel
"""

realestate.info()

realestate.describe()

"""##Missing Value"""

realestate = realestate.drop('No', axis=1)

realestate = realestate.rename(columns={
    'X1 transaction date': 'x1',
    'X2 house age': 'x2',
    'X3 distance to the nearest MRT station': 'x3',
    'X4 number of convenience stores': 'x4',
    'X5 latitude': 'x5',
    'X6 longitude': 'x6',
    'Y house price of unit area': 'y'
})

realestate

zero_value = (realestate == 0).sum()
zero_value

"""Tidak ada yang perlu dihapus dikarenakan umur rumah dan jumlah toko serba ada masuk akal memiliki nilai 0"""

duplicate_rows = realestate[realestate.duplicated()]

if not duplicate_rows.empty:
    print("Duplicate Rows:")
    print(duplicate_rows)
else:
    print("No duplicate rows found.")

realestate.shape

"""##Menangani Outliers"""

for column in realestate.columns:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=realestate[column])
    plt.title(f'Box Plot of {column}')
    plt.show()

"""###IQR Method"""

Q1 = realestate.quantile(0.25)
Q3 = realestate.quantile(0.75)
IQR=Q3-Q1
realestate=realestate[~((realestate<(Q1-1.5*IQR))|(realestate>(Q3+1.5*IQR))).any(axis=1)]

realestate.shape

"""##Feature Engineering

Penggunaan metode haversine untuk menghitung jarak antara pusat kota (Sindian Dist., New Taipei City, Taiwan) dengan fitur x5 dan x6 (Latitude dan Longitude)
"""

import numpy as np
from sklearn.metrics.pairwise import haversine_distances

pusat_kota = [121.5398, 24.9785]  # Sindian Dist., New Taipei City
kordinat = realestate[['x6', 'x5']].values  # Kolom x6 (longitude), x5 (latitude)

# Konversi ke radian
kordinat_radians = np.radians(kordinat)
pusat_kota_radians = np.radians(pusat_kota)

# Hitung jarak Haversine
jarak = haversine_distances(kordinat_radians, pusat_kota_radians.reshape(1, -1))

# Konversi ke kilometer (radius bumi = 6371 km)
jarak_km = jarak * 6371
realestate['jarak_ke_pusat(km)'] = jarak_km

print(realestate[['x5', 'x6', 'jarak_ke_pusat(km)']].head())

realestate = realestate.drop(['x5','x6'], axis=1)

realestate.head()

"""##Univariate Analysis"""

numerical_features = ['x1', 'x2', 'x3', 'jarak_ke_pusat(km)', 'y']
categorical_features = ['x4']

"""###Categorical Features"""

feature = categorical_features[0]
count = realestate[feature].value_counts()
percent = 100*realestate[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""###Numerical Features"""

realestate.hist(bins=50, figsize=(20,15))
plt.show()

"""##Multivariate Analysis

###Categorical Feature
"""

print(realestate.dtypes)

cat_features = realestate.select_dtypes(include='int64').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="y", kind="bar", dodge=False, height = 4, aspect = 3,  data=realestate, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

"""###Numerical Features"""

sns.pairplot(realestate, diag_kind = 'kde')

"""###Melihat Korelasi menggunakan metode spearman"""

plt.figure(figsize=(10, 8))
correlation_matrix = realestate[numerical_features].corr(method='spearman').round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

realestate.drop(['x1'], inplace=True, axis=1)
realestate.head()

"""#Data Preparation

##Encoding Fitur Kategori
"""

from sklearn.preprocessing import  OneHotEncoder
realestate = pd.concat([realestate, pd.get_dummies(realestate['x4'], prefix='x4').astype(int)], axis=1)
realestate.drop(['x4'], axis=1, inplace=True)
realestate.head()

"""##Train-Test-Split"""

from sklearn.model_selection import train_test_split

X = realestate.drop(["y"],axis =1)
y = realestate["y"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 122)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""##Standarisasi fitur"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['x2', 'x3', 'jarak_ke_pusat(km)']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(3)

"""##PCA

###Data Train
"""

sns.pairplot(X_train[['x3','jarak_ke_pusat(km)']], plot_kws={"s": 2});

from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=123)
pca.fit(X_train[['x3','jarak_ke_pusat(km)']])
princ_comp = pca.transform(X_train[['x3','jarak_ke_pusat(km)']])

pca.explained_variance_ratio_.round(2)

from sklearn.decomposition import PCA
pca = PCA(n_components=1, random_state=123)
pca.fit(X_train[['x3','jarak_ke_pusat(km)']])
X_train['akses_MRT_ke_pusat'] = pca.transform(X_train.loc[:, ('x3','jarak_ke_pusat(km)')]).flatten()
X_train.drop(['x3','jarak_ke_pusat(km)'], axis=1, inplace=True)

"""#Model Development"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""##Model Development dengan K-Nearest Neighbor"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=15)
knn.fit(X_train, y_train)

models.loc['train_mse','KNN'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""##Model Development dengan Random Forest"""

from sklearn.ensemble import RandomForestRegressor

RF = RandomForestRegressor(n_estimators=20, max_depth=5, random_state=35, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""##Model Development dengan Boosting Algorithm"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(n_estimators=300,
                             learning_rate=0.01,
                             random_state=42)

boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""##Evaluasi Model

### Scaling tes data
"""

X_test[numerical_features] = scaler.transform(X_test.loc[:, numerical_features])
X_test[numerical_features].head()

X_test[numerical_features].describe().round(3)

"""###PCA pada data tes"""

from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=123)
pca.fit(X_test[['x3','jarak_ke_pusat(km)']])
princ_comp = pca.transform(X_test[['x3','jarak_ke_pusat(km)']])

pca.explained_variance_ratio_.round(2)

from sklearn.decomposition import PCA
pca = PCA(n_components=1, random_state=123)
pca.fit(X_test[['x3','jarak_ke_pusat(km)']])
X_test['akses_MRT_ke_pusat'] = pca.transform(X_test.loc[:, ('x3','jarak_ke_pusat(km)')]).flatten()
X_test.drop(['x3','jarak_ke_pusat(km)'], axis=1, inplace=True)

"""### Hasil Evaluasi"""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(X_test).round(1)

pd.DataFrame(pred_dict)

pred_dict = {
    'y_true': y_test
}

for name, model in model_dict.items():
    pred_dict[f'prediksi_{name}'] = model.predict(X_test).round(1)

pred_df = pd.DataFrame(pred_dict)

model_names = [col for col in pred_df.columns if col.startswith('prediksi_')]
for model in model_names:
    pred_df[f'error_{model}'] = np.abs(pred_df['y_true'] - pred_df[model])

pred_df['best_model'] = pred_df[[f'error_{model}' for model in model_names]].idxmin(axis=1)

conf_matrix = pd.DataFrame(
    {model: [(pred_df['best_model'] == f'error_{model}').sum() for model in model_names]},
    index=model_names
)

print("Confusion Matrix Berdasarkan Selisih Terkecil:")
print(conf_matrix)

gridtuning = pd.DataFrame(index=['KNN', 'RF', 'Adaboost'], columns=['train_mse', 'test_mse'])

from sklearn.model_selection import GridSearchCV

param_grid_knn = {
    'n_neighbors': [3, 5, 7, 9, 11, 13, 15]
}

knn = KNeighborsRegressor()

grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_knn.fit(X_train, y_train)

gridtuning.loc['KNN', 'train_mse'] = mean_squared_error(y_pred=grid_search_knn.predict(X_train), y_true=y_train)
gridtuning.loc['KNN', 'test_mse'] = mean_squared_error(y_pred=grid_search_knn.predict(X_test), y_true=y_test)

param_grid_rf = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

rf = RandomForestRegressor(random_state=35, n_jobs=-1)

grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_rf.fit(X_train, y_train)

gridtuning.loc['RF', 'train_mse'] = mean_squared_error(y_pred=grid_search_rf.predict(X_train), y_true=y_train)
gridtuning.loc['RF', 'test_mse'] = mean_squared_error(y_pred=grid_search_rf.predict(X_test), y_true=y_test)

param_grid_ada = {
    'n_estimators': [50, 100, 200, 300],
    'learning_rate': [0.01, 0.1, 1.0]
}

ada = AdaBoostRegressor(random_state=42)

grid_search_ada = GridSearchCV(ada, param_grid_ada, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_ada.fit(X_train, y_train)

gridtuning.loc['Adaboost', 'train_mse'] = mean_squared_error(y_pred=grid_search_ada.predict(X_train), y_true=y_train)
gridtuning.loc['Adaboost', 'test_mse'] = mean_squared_error(y_pred=grid_search_ada.predict(X_test), y_true=y_test)

gridtuning

fig, ax = plt.subplots()
gridtuning.sort_values(by='test_mse', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

pred_dict_grid = {'y_true': y_test}

model_dict_grid = {
    'KNN': grid_search_knn,
    'RF': grid_search_rf,
    'Adaboost': grid_search_ada
}

for name, model in model_dict_grid.items():
    pred_dict_grid[f'prediksi_{name}'] = model.predict(X_test).round(1)

pred_df_grid = pd.DataFrame(pred_dict_grid)
pred_df_grid

for name, model in model_dict_grid.items():
    pred_dict_grid[f'prediksi_{name}'] = model.predict(X_test).round(1)

pred_df = pd.DataFrame(pred_dict_grid)

model_names = [col for col in pred_df.columns if col.startswith('prediksi_')]
for model in model_names:
    pred_df[f'error_{model}'] = np.abs(pred_df['y_true'] - pred_df[model])

pred_df['best_model'] = pred_df[[f'error_{model}' for model in model_names]].idxmin(axis=1)

conf_matrix = pd.DataFrame(
    {model: [(pred_df['best_model'] == f'error_{model}').sum() for model in model_names]},
    index=model_names
)

print("Confusion Matrix Berdasarkan Selisih Terkecil:")
print(conf_matrix)